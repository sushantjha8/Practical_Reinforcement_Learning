{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This Notebook defines training of model using ignite method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-y3EF0cpHbV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ONctZpJAr1PC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-ignite in c:\\users\\sushant\\anaconda3\\lib\\site-packages (0.5.0)\n",
            "Requirement already satisfied: torch<3,>=1.3 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from pytorch-ignite) (2.1.0+cu121)\n",
            "Requirement already satisfied: packaging in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from pytorch-ignite) (23.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from torch<3,>=1.3->pytorch-ignite) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from torch<3,>=1.3->pytorch-ignite) (4.7.1)\n",
            "Requirement already satisfied: sympy in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from torch<3,>=1.3->pytorch-ignite) (1.11.1)\n",
            "Requirement already satisfied: networkx in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from torch<3,>=1.3->pytorch-ignite) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from torch<3,>=1.3->pytorch-ignite) (2023.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (2.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from sympy->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n",
            "Requirement already satisfied: tensorboard in c:\\users\\sushant\\anaconda3\\lib\\site-packages (2.15.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from tensorboard) (2.0.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from tensorboard) (1.59.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from tensorboard) (2.23.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from tensorboard) (1.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from tensorboard) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from tensorboard) (1.24.3)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from tensorboard) (4.23.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from tensorboard) (68.0.0)\n",
            "Requirement already satisfied: six>1.9 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from tensorboard) (2.2.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-ignite\n",
        "! pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PVrVpSFAr2qA"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from transformers import ViTFeatureExtractor, ViTForImageClassification,AutoFeatureExtractor,AdamW\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import ViTImageProcessor, ViTModel\n",
        "from PIL import Image\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NiZ9nru4sAIO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA is available. Using GPU.\n"
          ]
        }
      ],
      "source": [
        "# Check if CUDA (GPU support) is available\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    print(\"CUDA is available. Using GPU.\")\n",
        "else:\n",
        "\n",
        "    print(\"CUDA is not available. Using CPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eALsUVvhsJRW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\sushant\\anaconda3\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ViTForImageClassification(\n",
              "  (vit): ViTModel(\n",
              "    (embeddings): ViTEmbeddings(\n",
              "      (patch_embeddings): ViTPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "      )\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): ViTEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x ViTLayer(\n",
              "          (attention): ViTAttention(\n",
              "            (attention): ViTSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): ViTSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ViTIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ViTOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "\n",
        "# Load pre-trained feature extractor\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
        "\n",
        "# Step 1: Modify classification head for the new number of classes\n",
        "num_classes = 10  # Update with your new number of classes\n",
        "model.classifier = torch.nn.Linear(model.config.hidden_size, num_classes)\n",
        "model.config.image_size=32\n",
        "# Move the model to the desired device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gM7NnAUosX4f"
      },
      "outputs": [],
      "source": [
        "index_to_label = {\n",
        "    0: 'Airplane',\n",
        "    1: 'Automobile',\n",
        "    2: 'Bird',\n",
        "    3: 'Cat',\n",
        "    4: 'Deer',\n",
        "    5: 'Dog',\n",
        "    6: 'Frog',\n",
        "    7: 'Horse',\n",
        "    8: 'Ship',\n",
        "    9: 'Truck'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QjDmPU5DslGv"
      },
      "outputs": [],
      "source": [
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Accuracy,Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z4vxSFSGsplQ"
      },
      "outputs": [],
      "source": [
        "from ignite.handlers import ModelCheckpoint\n",
        "from ignite.contrib.handlers import TensorboardLogger, global_step_from_engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HSR3xeK7sd4A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Create the dataset and data loaders\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = model  # Initialize your ViT model here\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def score_function(engine):\n",
        "    return (engine.state.metrics['accuracy'] + engine.state.metrics['auc']) / 2\n",
        "    #return engine.state.metrics['accuracy']\n",
        "val_metrics = {\n",
        "    \"accuracy\": Accuracy(),\n",
        "    \"loss\": Loss(criterion)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "x5vCdbUysqKa"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from ignite.engine import Engine\n",
        "from torch.nn.utils import clip_grad_norm\n",
        "\n",
        "def train_step(engine, batch):\n",
        "    model.train()\n",
        "    inputs, targets = batch\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs.to(device))\n",
        "    logits = outputs.logits if hasattr(outputs, \"logits\") else outputs.last_hidden_state\n",
        "    probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
        "    loss = criterion(probabilities, targets)\n",
        "    loss.backward()\n",
        "    # Gradient Clipping\n",
        "    clip_grad_norm(model.parameters(), max_norm=1.0)  # Adjust max_norm as needed\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "# Create Ignite trainer and evaluator\n",
        "trainer = Engine(train_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "J9VC5mueszZW"
      },
      "outputs": [],
      "source": [
        "def validation_step(engine, batch):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x, y= batch\n",
        "        y_pred = model(x.to(device))\n",
        "\n",
        "    return y_pred, y\n",
        "\n",
        "\n",
        "evaluator = Engine(validation_step)\n",
        "# Attach metrics to the evaluators\n",
        "for name, metric in val_metrics.items():\n",
        "    metric.attach(evaluator, name)\n",
        "\n",
        "for name, metric in val_metrics.items():\n",
        "    metric.attach(evaluator, name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [],
      "source": [
        "# How many batches to wait before logging training status\n",
        "log_interval = 100\n",
        "@trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n",
        "def log_training_loss(engine):\n",
        "    print(f\"Epoch[{engine.state.epoch}], Iter[{engine.state.iteration}] Loss: {engine.state.output:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "3_i_Zh_ns3tR"
      },
      "outputs": [],
      "source": [
        "from ignite.engine import Events\n",
        "from ignite.metrics import Accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<ignite.engine.events.RemovableEventHandle at 0x1625dbde210>"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# def log_training_loss(engine):\n",
        "#     print(f\"Epoch[{engine.state.epoch}], Iter[{engine.state.iteration}] Loss: {engine.state.output:.2f}\")\n",
        "\n",
        "# trainer.add_event_handler(Events.ITERATION_COMPLETED, log_training_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "trainer vs. evaluator: In Ignite, the `trainer` refers to the engine responsible for the training loop, while the `evaluator` refers to the engine responsible for evaluation (validation or testing). They are separate engines with distinct roles.\n",
        "\n",
        "The trainer is responsible for training the model using the training data loader and the specified training logic (train_step function).\n",
        "The evaluator is responsible for evaluating the model using the validation or test data loader and the specified evaluation logic (validation_step function)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "de3j2oudzfxT"
      },
      "outputs": [],
      "source": [
        "# Reinforcement Learning Setup\n",
        "reward_window = []\n",
        "best_accuracy = 0.0\n",
        "Accuracy().attach(evaluator, \"accuracy\")\n",
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def log_training_results(trainer):\n",
        "    trainer.run(train_loader)\n",
        "    metrics = trainer.state.metrics\n",
        "    print(f\"Training Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy']:.2f} Avg loss: {metrics['loss']:.2f}\")\n",
        "\n",
        "\n",
        "# @trainer.on(Events.EPOCH_STARTED)\n",
        "# def log_validation_results(evaluator):\n",
        "#     evaluator.run(test_loader)\n",
        "#     metrics = evaluator.state.metrics\n",
        "#     print(f\"Validation Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy']:.2f} Avg loss: {metrics['loss']:.2f}\")\n",
        "\n",
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def update_with_reward(evaluator):\n",
        "    print(\"done\")\n",
        "    global best_accuracy\n",
        "    # we will not run evaluator as already used evlutor in above\n",
        "    # Use the validation accuracy as the reward\n",
        "    reward = evaluator.state.metrics['accuracy']\n",
        "\n",
        "    # Update the model based on the reward\n",
        "    if reward > best_accuracy:\n",
        "        best_accuracy = reward\n",
        "        print(f\"Updating model with reward: {reward}\")\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K37HZKmbXyaM"
      },
      "outputs": [],
      "source": [
        "!pip install jupyter-tensorboard\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Iginte Event Management\n",
        "\n",
        "* Events.STARTED: Triggered when the engine is started.\n",
        "* Events.COMPLETED: Triggered when the engine is completed.\n",
        "* Events.EPOCH_STARTED: Triggered at the beginning of each epoch.\n",
        "* Events.EPOCH_COMPLETED: Triggered at the end of each epoch.\n",
        "* Events.ITERATION_STARTED: Triggered at the beginning of each iteration (batch).\n",
        "* Events.ITERATION_COMPLETED: Triggered at the end of each iteration (batch).\n",
        "* Events.EXCEPTION_RAISED: Triggered when an exception is raised in the engine.\n",
        "* Events.TERMINATE: Triggered when the engine should terminate.\n",
        "* Events.MODEL_CHECKPOINT: Triggered when a model checkpoint is about to be saved.\n",
        "* Events.REDUCE_LR_ON_PLATEAU: Triggered during the learning rate reduction on plateau."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "KUA3gdAfYY91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "oQ51fr9_Xjrd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<ignite.engine.events.RemovableEventHandle at 0x1625dc4e010>"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_checkpoint = ModelCheckpoint(\n",
        "    \"checkpoint\",\n",
        "    n_saved=2,\n",
        "    filename_prefix=\"best\",\n",
        "    score_function=score_function,\n",
        "    score_name=\"accuracy\",\n",
        "    global_step_transform=global_step_from_engine(trainer),\n",
        ")\n",
        "\n",
        "# Save the model after every epoch of val_evaluator is completed\n",
        "evaluator.add_event_handler(Events.COMPLETED, model_checkpoint, {\"model\": model})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "pZ73g6HZ1_R5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<ignite.engine.events.RemovableEventHandle at 0x1625dc98990>"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ignite.contrib.handlers import TensorboardLogger, global_step_from_engine\n",
        "tb_logger = TensorboardLogger(log_dir=\"tb-logger\")\n",
        "\n",
        "# Attach TensorBoard logger for loss, accuracy, and AUC\n",
        "tb_logger.attach_output_handler(\n",
        "    trainer,\n",
        "    event_name=Events.ITERATION_COMPLETED(every=100),\n",
        "    tag=\"training\",\n",
        "    output_transform=lambda loss: {\"batch_loss\": loss},\n",
        ")\n",
        "\n",
        "tb_logger.attach_output_handler(\n",
        "    evaluator,\n",
        "    event_name=Events.EPOCH_COMPLETED,\n",
        "    tag=\"validation\",\n",
        "    metric_names=['loss', 'accuracy', 'auc'],\n",
        "    global_step_transform=global_step_from_engine(trainer),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Attach handler for plotting both evaluators' metrics after every epoch completes\n",
        "for tag, evaluator in [(\"training\", trainer), (\"validation\", evaluator)]:\n",
        "    tb_logger.attach_output_handler(\n",
        "        evaluator,\n",
        "        event_name=Events.EPOCH_COMPLETED,\n",
        "        tag=tag,\n",
        "        metric_names=\"all\",\n",
        "        global_step_transform=global_step_from_engine(trainer),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ignite.contrib.handlers import ProgressBar\n",
        "\n",
        "ProgressBar().attach(trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "Y7rATR5HzAO-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sushant\\AppData\\Local\\Temp\\ipykernel_12020\\2996972786.py:15: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  clip_grad_norm(model.parameters(), max_norm=1.0)  # Adjust max_norm as needed\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9c7b6eb7ea14c3abb5520e10d8e4dd1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/6250]   0%|           [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Run the training loop\n",
        "trainer.run(train_loader, max_epochs=6)\n",
        "tb_logger.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyWRCmYq1-KL"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir=./tb-logger"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
