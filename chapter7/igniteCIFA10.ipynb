{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKljKKdDozao"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-y3EF0cpHbV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ONctZpJAr1PC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-ignite in c:\\users\\sushant\\anaconda3\\lib\\site-packages (0.5.0)\n",
            "Requirement already satisfied: torch<3,>=1.3 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from pytorch-ignite) (2.1.0+cu121)\n",
            "Requirement already satisfied: packaging in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from pytorch-ignite) (23.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from torch<3,>=1.3->pytorch-ignite) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from torch<3,>=1.3->pytorch-ignite) (4.7.1)\n",
            "Requirement already satisfied: sympy in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from torch<3,>=1.3->pytorch-ignite) (1.11.1)\n",
            "Requirement already satisfied: networkx in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from torch<3,>=1.3->pytorch-ignite) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from torch<3,>=1.3->pytorch-ignite) (2023.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (2.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from sympy->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n",
            "Collecting tensorboard\n",
            "  Obtaining dependency information for tensorboard from https://files.pythonhosted.org/packages/6e/0c/1059a6682cf2cc1fcc0d5327837b5672fe4f5574255fa5430d0a8ceb75e9/tensorboard-2.15.1-py3-none-any.whl.metadata\n",
            "  Downloading tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting absl-py>=0.4 (from tensorboard)\n",
            "  Obtaining dependency information for absl-py>=0.4 from https://files.pythonhosted.org/packages/01/e4/dc0a1dcc4e74e08d7abedab278c795eef54a224363bb18f5692f416d834f/absl_py-2.0.0-py3-none-any.whl.metadata\n",
            "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard)\n",
            "  Obtaining dependency information for grpcio>=1.48.2 from https://files.pythonhosted.org/packages/bc/e5/f656b17fe1ccda1e2a4fe20298b8bcf7c804561c90ee763e39efc1c3772f/grpcio-1.59.3-cp311-cp311-win_amd64.whl.metadata\n",
            "  Downloading grpcio-1.59.3-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
            "Collecting google-auth<3,>=1.6.3 (from tensorboard)\n",
            "  Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/86/a7/75911c13a242735d5aeaca6a272da380335ff4ba5f26d6b2ae20ff682d13/google_auth-2.23.4-py2.py3-none-any.whl.metadata\n",
            "  Downloading google_auth-2.23.4-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard)\n",
            "  Obtaining dependency information for google-auth-oauthlib<2,>=0.5 from https://files.pythonhosted.org/packages/ce/33/a907b4b67245647746dde8d61e1643ef5d210c88e090d491efd89eff9f95/google_auth_oauthlib-1.1.0-py2.py3-none-any.whl.metadata\n",
            "  Downloading google_auth_oauthlib-1.1.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from tensorboard) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from tensorboard) (1.24.3)\n",
            "Collecting protobuf<4.24,>=3.19.6 (from tensorboard)\n",
            "  Obtaining dependency information for protobuf<4.24,>=3.19.6 from https://files.pythonhosted.org/packages/80/70/dc63d340d27b8ff22022d7dd14b8d6d68b479a003eacdc4507150a286d9a/protobuf-4.23.4-cp310-abi3-win_amd64.whl.metadata\n",
            "  Downloading protobuf-4.23.4-cp310-abi3-win_amd64.whl.metadata (540 bytes)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from tensorboard) (68.0.0)\n",
            "Requirement already satisfied: six>1.9 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from tensorboard) (1.16.0)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
            "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/7a/13/e503968fefabd4c6b2650af21e110aa8466fe21432cd7c43a84577a89438/tensorboard_data_server-0.7.2-py3-none-any.whl.metadata\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from tensorboard) (2.2.3)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard)\n",
            "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a2/91/2d843adb9fbd911e0da45fbf6f18ca89d07a087c3daa23e955584f90ebf4/cachetools-5.3.2-py3-none-any.whl.metadata\n",
            "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard)\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard)\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sushant\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard)\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "     ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
            "     -------------------------------------- 151.7/151.7 kB 9.4 MB/s eta 0:00:00\n",
            "Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
            "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
            "   ---- ----------------------------------- 0.6/5.5 MB 20.1 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 1.8/5.5 MB 23.1 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 3.8/5.5 MB 30.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  5.5/5.5 MB 35.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 5.5/5.5 MB 29.6 MB/s eta 0:00:00\n",
            "Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
            "   ---------------------------------------- 0.0/130.2 kB ? eta -:--:--\n",
            "   ---------------------------------------- 130.2/130.2 kB 7.5 MB/s eta 0:00:00\n",
            "Downloading google_auth-2.23.4-py2.py3-none-any.whl (183 kB)\n",
            "   ---------------------------------------- 0.0/183.3 kB ? eta -:--:--\n",
            "   --------------------------------------- 183.3/183.3 kB 11.5 MB/s eta 0:00:00\n",
            "Downloading google_auth_oauthlib-1.1.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading grpcio-1.59.3-cp311-cp311-win_amd64.whl (3.7 MB)\n",
            "   ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
            "   ------------ --------------------------- 1.2/3.7 MB 76.5 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 2.4/3.7 MB 31.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------  3.7/3.7 MB 29.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 3.7/3.7 MB 29.3 MB/s eta 0:00:00\n",
            "Downloading protobuf-4.23.4-cp310-abi3-win_amd64.whl (422 kB)\n",
            "   ---------------------------------------- 0.0/422.5 kB ? eta -:--:--\n",
            "   --------------------------------------- 422.5/422.5 kB 25.8 MB/s eta 0:00:00\n",
            "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
            "Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
            "Installing collected packages: tensorboard-data-server, rsa, protobuf, oauthlib, grpcio, cachetools, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard\n",
            "Successfully installed absl-py-2.0.0 cachetools-5.3.2 google-auth-2.23.4 google-auth-oauthlib-1.1.0 grpcio-1.59.3 oauthlib-3.2.2 protobuf-4.23.4 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.1 tensorboard-data-server-0.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-ignite\n",
        "! pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PVrVpSFAr2qA"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from transformers import ViTFeatureExtractor, ViTForImageClassification,AutoFeatureExtractor,AdamW\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import ViTImageProcessor, ViTModel\n",
        "from PIL import Image\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NiZ9nru4sAIO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA is available. Using GPU.\n"
          ]
        }
      ],
      "source": [
        "# Check if CUDA (GPU support) is available\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    print(\"CUDA is available. Using GPU.\")\n",
        "else:\n",
        "\n",
        "    print(\"CUDA is not available. Using CPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eALsUVvhsJRW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\sushant\\anaconda3\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ViTForImageClassification(\n",
              "  (vit): ViTModel(\n",
              "    (embeddings): ViTEmbeddings(\n",
              "      (patch_embeddings): ViTPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "      )\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): ViTEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x ViTLayer(\n",
              "          (attention): ViTAttention(\n",
              "            (attention): ViTSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): ViTSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ViTIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ViTOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "\n",
        "# Load pre-trained feature extractor\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
        "\n",
        "# Step 1: Modify classification head for the new number of classes\n",
        "num_classes = 10  # Update with your new number of classes\n",
        "model.classifier = torch.nn.Linear(model.config.hidden_size, num_classes)\n",
        "model.config.image_size=32\n",
        "# Move the model to the desired device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gM7NnAUosX4f"
      },
      "outputs": [],
      "source": [
        "index_to_label = {\n",
        "    0: 'Airplane',\n",
        "    1: 'Automobile',\n",
        "    2: 'Bird',\n",
        "    3: 'Cat',\n",
        "    4: 'Deer',\n",
        "    5: 'Dog',\n",
        "    6: 'Frog',\n",
        "    7: 'Horse',\n",
        "    8: 'Ship',\n",
        "    9: 'Truck'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QjDmPU5DslGv"
      },
      "outputs": [],
      "source": [
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Accuracy,Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "z4vxSFSGsplQ"
      },
      "outputs": [],
      "source": [
        "from ignite.handlers import ModelCheckpoint\n",
        "from ignite.contrib.handlers import TensorboardLogger, global_step_from_engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HSR3xeK7sd4A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Create the dataset and data loaders\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = model  # Initialize your ViT model here\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def score_function(engine):\n",
        "    return engine.state.metrics[\"accuracy\"]\n",
        "val_metrics = {\n",
        "    \"accuracy\": Accuracy(),\n",
        "    \"loss\": Loss(criterion)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "x5vCdbUysqKa"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from ignite.engine import Engine\n",
        "\n",
        "\n",
        "def train_step(engine, batch):\n",
        "    model.train()\n",
        "    inputs, targets = batch\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs.to(device))\n",
        "    logits = outputs.logits if hasattr(outputs, \"logits\") else outputs.last_hidden_state\n",
        "    probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
        "    loss = criterion(probabilities, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "# Create Ignite trainer and evaluator\n",
        "trainer = Engine(train_step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "J9VC5mueszZW"
      },
      "outputs": [],
      "source": [
        "def validation_step(engine, batch):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x, y= batch\n",
        "        y_pred = model(x.to(device))\n",
        "\n",
        "    return y_pred, y.to(device)\n",
        "\n",
        "\n",
        "evaluator = Engine(validation_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3_i_Zh_ns3tR"
      },
      "outputs": [],
      "source": [
        "from ignite.engine import Events\n",
        "\n",
        "validate_every = 10\n",
        "\n",
        "\n",
        "@trainer.on(Events.EPOCH_COMPLETED(every=validate_every))\n",
        "def run_validation():\n",
        "    evaluator.run(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "de3j2oudzfxT"
      },
      "outputs": [],
      "source": [
        "@trainer.on(Events.EPOCH_COMPLETED(every=validate_every))\n",
        "def log_validation():\n",
        "    metrics = evaluator.state.metrics\n",
        "    print(f\"Epoch: {trainer.state.epoch},  Accuracy: {metrics['accuracy']}\")\n",
        "from ignite.metrics import Accuracy\n",
        "\n",
        "Accuracy().attach(evaluator, \"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K37HZKmbXyaM"
      },
      "outputs": [],
      "source": [
        "!pip install jupyter-tensorboard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KUA3gdAfYY91"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "oQ51fr9_Xjrd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<ignite.engine.events.RemovableEventHandle at 0x1e27fd6fa90>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_checkpoint = ModelCheckpoint(\n",
        "    \"checkpoint\",\n",
        "    n_saved=2,\n",
        "    filename_prefix=\"best\",\n",
        "    score_function=score_function,\n",
        "    score_name=\"accuracy\",\n",
        "    global_step_transform=global_step_from_engine(trainer),\n",
        ")\n",
        "\n",
        "evaluator.add_event_handler(Events.COMPLETED, model_checkpoint, {\"model\": model})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "pZ73g6HZ1_R5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<ignite.engine.events.RemovableEventHandle at 0x1e2683f9190>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ignite.contrib.handlers import TensorboardLogger, global_step_from_engine\n",
        "tb_logger = TensorboardLogger(log_dir=\"tb-logger\")\n",
        "\n",
        "tb_logger.attach_output_handler(\n",
        "    trainer,\n",
        "    event_name=Events.ITERATION_COMPLETED(every=100),\n",
        "    tag=\"training\",\n",
        "    output_transform=lambda loss: {\"batch_loss\": loss},\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Y7rATR5HzAO-"
      },
      "outputs": [],
      "source": [
        "# Reinforcement Learning Setup\n",
        "reward_window = []\n",
        "best_accuracy = 0.0\n",
        "\n",
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def update_with_reward(engine):\n",
        "    print(\"done\")\n",
        "    global best_accuracy\n",
        "\n",
        "    # Use the validation accuracy as the reward\n",
        "    reward = evaluator.state.metrics['accuracy']\n",
        "\n",
        "    # Update the model based on the reward\n",
        "    if reward > best_accuracy:\n",
        "        best_accuracy = reward\n",
        "        print(f\"Updating model with reward: {reward}\")\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "\n",
        "# Run the training loop\n",
        "trainer.run(train_loader, max_epochs=30)\n",
        "tb_logger.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyWRCmYq1-KL"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir=./tb-logger"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
